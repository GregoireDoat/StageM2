
\section{\todo Exemples d'applications} \label{sec:exemples_appli}

\subsection{\todo Cas 2D : lien avec la première partie} \label{subsec:ex-2D}

Rabi
\\ \\ \\
En mécanique quantique, les systèmes à deux niveaux sont à la base de l'information quantique. En effet, un tel système est l'archetype d'un qubit, pouvait encoder deux valeurs (0 et 1) par la présence des deux états du système. Ces systèmes sont centraux en théorie de l'information quantique du fait du principe de superposition qui assure que l'état est une superposition d'un 0 et d'un 1. La puissance de la théorie de l'information quantique est basée sur cette spécificité, qui n'existe pas pour les bits non-quantiques. Il existe de nombreux ouvrages qui décrivent la façon de transmettre l'information et la manipuler [ref,ref,ref].
Ici, nous nous intéressons au système à deux états, mais d'un point de vue déterministe. En fait, nous reprenons le modèle issu de la mécanique et montrons comment il permet d'avoir un modèle de signal bivarié possédant une phase géométrique. Cette phase est bien connue pour ces systèmes [Bohm] et nous reformulons ici les résultats donnés dans [ref gretsi] avec un formalisme légèrement différent.
\\ 

On considère un signal bivarié $x(t) \in C^2$, solution de l'equation différentielle du premier ordre suivante :(2) puis (3) de  \cite{le_bihan_modephysiques_2023}
\\ \\

Commentaire : 
\\ \\ \\
A partir de là, il faut réécrire en $\C^2$ à la place de H.
dans ce qui est écrit 

\[x(t) = x1(t) + i x2(t) \text{x(t) est donc quaternionique}\] 

avec $x1(t) = Re[x1(t)] + j Im[x1(t)]$

et pareil pour $x2(t)$.

---


Ensuite, il faut dérouler le petit calcul que j'ai fait dans la note manuscrite. 

Après ça raccroche avec le papier et il faut faire une figure avec les paramètres que tu veux dans le notebook et ça suffira. 



\section{\todo Pour la suite}\label{sec:2lasuite}


\subsection{\todo Limite du modèle}\label{subsec:limite2model}

\begin{itemize}
	
	\item $\PC{1} \cong S^2$ est super satisfaisant mais au dela c'est beaucoup moins claire.
	
	\item Pour passer de 2D à 3D, on a juste augmenté les matrices de rotation, \ie~$\SO(3)$ au lieu de $\SO(2)$. 
	
	\item C'est ce qu'on fait par Lilly \& Olhede \cite{lilly_modulated_2011} et Lefèvre a discuté des généralisations dans sa thèse \cite{lefevre_polarization_2021}
	
	\item Ca fait sens physiquement mais par rapport à $\PC{n}$ c'est loin d'être évident
	
	\item ... est-ce que c'est là que se cache le lien avec le double-cover de $\SO$ par $\SU$ ???
	\begin{itemize}
		\item Il serait vraiment intéressant (instructif) de faire ce lien 
		
		\item peut-être notre travail sur le phase g est une généralisation de ça ? 
	\end{itemize}
	
\end{itemize}



\subsection{\todo Rapport de la phase géométrique au bruit}\label{subsec:rapportObruit}

\begin{itemize}
	\item Si une source d'information n'est pas sensé changer d'état de polarisation, mais qu'on constate qu'il y a phase géométrique, alors ce n'est (quasiment) que du bruit. Ça peut donc être un premier filtre pour débruiter.
	\begin{itemize}
		
		\item pour le corriger en revanche, c'est un peu plus technique parce que ça veut dire qu'il faut tuer la polarisation du signal ou au moins la réduire à une géodésique.
		
		\item une idée serait de regarder la moyenne du signal projeté dans $\PC{n}$ et du tout simplement remplacer l'état de polarisation du signal par ca moyenne. 
		
		\item ca devrait pas affecter le phase dynamique	
	\end{itemize}
	
	\item En étant un peu moins restrictif l'évolution de l'état de polarisation du signal, on a vu qu'un la phase instantanée doit contenir les hautes fréquences du signal, Peut-être qu'on pourrait se servir de ça pour contraindre les variations de l'état de polar et, là encore, en faire un critère de débruitage.
	\begin{itemize}
		
		\item  par exemple en tuant les hautes fréquences de la phase géométrique
		
		\item d'ailleurs, ca amène la question : quide de faire du Fourier sur les phases ? La phase totale est pas très intéressante (j'imagine), mais les deux autres ? 
		
		\item c'est un peu flou quand-même parce $\phaseg$ vient de l'état de polar, qui lui n'est affecté parles transfo de jauge
	\end{itemize}
	
	\hrule
	
	\item Il faudrait voir comment la phase géométrique réagit au bruit.
	\begin{itemize}
		
		\item Si elle y est très résiliente, elle pourrait être source d'information sur des données. Voir même, être une information de base pour reconstruire une signal (genre en utilisant le fait qu'elle soit à propos des basse-fréquence)
		
		\item Plus généralement, il serait bien de voir comment elle réagit en fonction de la distribution spectrale du bruit
	\end{itemize}
	
\end{itemize}



\subsection{\todo Cas non commutatif}\label{subsec:non-commu}

\begin{itemize}
	
	\item En gros on va devoir aller Stiefel, aka $\PC{n}$ va devenir une grassmannienne $Stiefel/\U{k}$
	
	\item Fubini-Study s'étend à ces espaces, et les grassmannienne sont toujours des variétés complexes
	
	\item La formule de la phase dyn va changer par contre (path ordering) et donc son interprétations sera à revoir :/
	
	\item Autres potentielles applications :
	\begin{itemize}
		
		\item Subspace tracking
		
		\item ?
	\end{itemize}
	
\end{itemize}




\section{\todo Lien entre Poincaré et Bloch (EN VRAC)}

\thoughts{Un paquet de calculs, comme pour l'annexe A, il faudra que je le remette en forme , remette du contexte et que j'enlève des choses.}



\subsubsection{\todo Lien entre les deux types de signaux}

Soit le signal :
\[\x_B(\varphi, \theta, \chi) = e^{\i \varphi} \begin{pmatrix}
	\cos \chi/2 \\ e^{\i \theta}\sin\chi/2\end{pmatrix}\]
Pour le réécrire en terme de vecteur AM-FM-PM, il faut faire apparaître une matrice de rotation, matrice qui est diagonalisable dans $\C^{n\times n}$ via la relation :
\begin{align*}
	&\begin{pmatrix} 
		\cos \alpha & -\sin \alpha \\ 
		\sin\alpha & \cos\alpha 
	\end{pmatrix} = \frac{1}{2} \begin{pmatrix} 
		1 & -1 \\ i & i
	\end{pmatrix}\begin{pmatrix} 
		e^{-\i \alpha} & 0 \\ 
		0 & e^{\i \alpha} 
	\end{pmatrix}\begin{pmatrix} 
		1 & -i \\ -1 & -i
	\end{pmatrix}\\
	&\Llr\quad \begin{pmatrix} 
		1 & -i \\ -1 & -i
	\end{pmatrix}\begin{pmatrix} 
		\cos \alpha & -\sin \alpha \\ 
		\sin\alpha & \cos\alpha 
	\end{pmatrix} \begin{pmatrix} 
		1 & -1 \\ i & i
	\end{pmatrix} = 2 \begin{pmatrix} 
		e^{-\i \alpha} & 0 \\ 
		0 & e^{\i \alpha} 
	\end{pmatrix}
\end{align*}
\\
Cela permet d'écrire :
\begin{align*}
	\x_B(\varphi, \theta, \chi) &= e^{\i \varphi} e^{\i \theta/2}\begin{pmatrix}
		e^{-\i \theta/2} & 0 \\
		0 & e^{\i \theta/2}
	\end{pmatrix}\begin{pmatrix} 
		\cos \chi/2 \\ 
		\sin \chi/2 
	\end{pmatrix} \\
	&= \frac{1}{2}e^{\i \varphi} e^{\i \theta/2}\begin{pmatrix} 
		1 & -i \\
		-1 & -i
	\end{pmatrix}\begin{pmatrix} 
		\cos \theta/2 & -\sin \theta/2 \\ 
		\sin \theta/2 & \cos \theta/2 
	\end{pmatrix} \begin{pmatrix} 
		1 & -1 \\ i & i
	\end{pmatrix}\begin{pmatrix} 
		\cos \chi/2 \\ 
		\sin\chi/2
	\end{pmatrix} \\
	&= \frac{\sqrt{2}}{2}e^{\i (\varphi + \theta/2)}U R_{\theta/2} \begin{pmatrix} 
		\cos \chi/2 - \sin\chi/2 \\ 
		i\big(\cos\chi/2 + \sin\chi/2\big)
	\end{pmatrix}   & &\text{où }\quad U = \frac{\sqrt{2}}{2}\begin{pmatrix} 
		1 & -i \\ -1 & -i
	\end{pmatrix}\in \U{2} \\
\end{align*}
\\
Ensuite, pour réduire les sommes dans le vecteur de droite, on a rappel les formules :
\begin{align*}
	\cos\left( \frac{\pi}{2} \pm \alpha\right) &= \frac{\sqrt{2}}{2}\big( \cos\alpha \mp \sin \alpha \big) & \sin\left( \frac{\pi}{2} \pm \alpha\right) &= \frac{\sqrt{2}}{2}\big( \cos\alpha \pm \sin \alpha \big)
\end{align*}
\\ 
On a donc deux choix pour chaque composante du vecteur mais celle avec un signe moins son préférable sachant que : 
\begin{align*}
	\cos\left( \frac{\pi}{2} - \alpha\right) &= \sin(\alpha) &  \sin\left( \frac{\pi}{2} - \alpha\right) &= \cos(\alpha)
\end{align*}
\\
On choisi donc la seconde formule pour la première composante et la premier pour la seconde composante, donnant :
\begin{align*}
	\x_B(\varphi, \theta, \chi) &= \frac{\sqrt{2}}{2}e^{\i (\varphi + \theta/2)}U R_{\theta/2} \begin{pmatrix} 
		\cos \chi/2 - \sin\chi/2 \\ 
		i\big(\cos\chi/2 + \sin\chi/2\big)
	\end{pmatrix} \\
	&= e^{\i (\varphi + \theta/2)}U R_{\theta/2} \begin{pmatrix} 
		\sin\left( \frac{\pi}{2} - \chi/2\right) \\ 
		i\cos\left( \frac{\pi}{2} - \chi/2\right)
	\end{pmatrix} \\
	&= e^{\i (\varphi + \theta/2)}U R_{\theta/2} \begin{pmatrix} 
		\cos \chi/2 \\ 
		i\sin \chi/2
	\end{pmatrix}
\end{align*}
\\
Ne reste alors plus qu'à ajuster les signes pour obtenir une écriture de signal $\x_P$ AM-FM-PM :
\begin{align*}
	\x_B(\varphi, \theta, \chi) &= e^{\i (\varphi + \theta/2)}U R_{\theta/2} \begin{pmatrix} 
		\cos \chi/2 \\ 
		i\sin \chi/2
	\end{pmatrix} \\
	&= U e^{\i (\varphi + \theta/2)} R_{\theta/2} \begin{pmatrix} 
		\cos (-\chi/2) \\ 
		-i\sin (-\chi/2)
	\end{pmatrix}
\end{align*}
En somme :
\begin{align} \label{eq:bloch2poinca}
	\x_B(\psi, \alpha, \beta) &= U \x_P(\psi + \alpha/2, \alpha/2, -\beta/2)  & 
	\x_P(\varphi, \theta, \chi) = U^\dagger 	\x_B(\varphi-\theta, 2\theta, -2\chi)	
\end{align}
\skipl 



\subsubsection{\todo Lien entre les projections}

Avec la formule \eqref{eq:bloch2poinca} ci-dessus, on a :

\begin{align}
	\rho_B(\alpha, \beta) &= U \rho_P(\alpha/2, -\beta/2)U^\dagger  & 
	\rho_P(\theta, \chi) &= U^\dagger \rho_B(2\theta, -2\chi) U
	%\\ \Llr\ \rho_B(\alpha, \beta) U &= U \rho_P(\alpha/2, -\beta/2) & \Llr\ \rho_P(\theta, \chi) U^\dagger &= U^\dagger \rho_B(2\theta, -2\chi) 
\end{align}
\\
Mais on a aussi, dans la base Pauli :
\begin{align*}
	\sigma_1 &= \begin{pmatrix} 0 & 1 \\ 1 &  0 \end{pmatrix}  &
	\sigma_2 &= \begin{pmatrix} 0 & -i \\  i &  0 \end{pmatrix}  &
	\sigma_3 &= \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix}
\end{align*}
les expressions :
\begin{align*}
	\rho_{P}(\theta, \chi) &= \frac{1}{2} \Big( id + \sin(2\theta) \cos(2\chi) \sigma_1 - \sin (2\chi) \sigma_2 + \cos(2\theta) \cos(2\chi) \sigma_3 \Big) \\ 
	\rho_{B}(\alpha, \beta) &= \frac{1}{2} \Big( id + \cos(\alpha) \sin(\beta) \sigma_1 + \sin(\alpha) \sin(\beta) \sigma_2 + \cos (\beta) \sigma_3 \Big)
\end{align*}
\skipl

Pour les lier, on pose $\ 2\theta = \nicefrac{\pi}{2} - \alpha\ $ et $\ 2\chi = \nicefrac{\pi}{2} - \beta$, donnant :
\begin{align*}
	\rho_P(\theta, \chi) - id 
	&= \sin(\nicefrac{\pi}{2} - \alpha) \cos(\nicefrac{\pi}{2} - \beta) \sigma_1 - \sin (\nicefrac{\pi}{2} - \beta) \sigma_2 + \cos(\nicefrac{\pi}{2} - \alpha) \cos(\nicefrac{\pi}{2} - \beta) \sigma_3 \\
	&= \cos(\alpha) \sin(\beta) \sigma_1 - \cos (\beta) \sigma_2 + \sin(\alpha) \sin(\beta) \sigma_3
\end{align*}
\\
Ce qui sous forme matricielle se réécrit :
\[\begin{pmatrix}
	\sin(2\theta) \cos(2\chi) \\ -\sin (2\chi) \\ \cos(2\theta) \cos(2\chi)
\end{pmatrix} = \begin{pmatrix}
	\cos(\alpha) \sin(\beta) \\ -\cos (\beta) \\ \sin(\alpha) \sin(\beta)
\end{pmatrix} = \begin{pmatrix}
	1 & 0 & 0 \\ 0 & 0 & -1 \\ 0 & 1 & 0
\end{pmatrix}\begin{pmatrix}
	\cos(\alpha) \sin(\beta) \\ \sin(\alpha) \sin(\beta) \\ \cos (\beta)
\end{pmatrix}\]
\\
Donc la passage de $\rho_B$ à $\rho_S$ se fait via un changement et d'angle et une rotation de $\nicefrac{\pi}{2}$ autour de $\sigma_1$.
\\

Même calcul, cette fois, en partant de \eqref{eq:bloch2poinca} :
\begin{align*}
	2\rho_P(\theta, \chi) &= 2U^\dagger \rho_B(2\theta, -2\chi) U \\
	&= U^\dagger \Big( id + \cos(2\theta) \sin(-2\chi) \sigma_1 + \sin(2\theta) \sin(-2\chi) \sigma_2 + \cos (-2\chi) \sigma_3 \Big) U \\
	&= id - \cos(2\theta) \sin(2\chi) U^\dagger \sigma_1 U - \sin(2\theta) \sin(2\chi) U^\dagger \sigma_2 U + \cos (2\chi) U^\dagger \sigma_3 U
\end{align*}
avec :
\begin{align*}
	U^\dagger \sigma_1 U &= \frac{1}{2} \begin{pmatrix} 
		1 & -1 \\ i & i
	\end{pmatrix} \begin{pmatrix} 
		0 & 1 \\ 1 &  0 
	\end{pmatrix} \begin{pmatrix} 
		1 & -i \\ -1 & -i
	\end{pmatrix} = \frac{1}{2} \begin{pmatrix} 
		-2 & 0 \\ 0 & 2
	\end{pmatrix} = -\sigma_3 \\
	U^\dagger \sigma_2 U &= \frac{1}{2} \begin{pmatrix} 
		1 & -1 \\ i & i
	\end{pmatrix} \begin{pmatrix} 
		0 & -i \\  i &  0 
	\end{pmatrix} \begin{pmatrix} 
		1 & -i \\ -1 & -i
	\end{pmatrix} = \frac{1}{2} \begin{pmatrix} 
		0 & -2 \\ -2 & 0
	\end{pmatrix} = -\sigma_1 \\
	U^\dagger \sigma_3 U &= \frac{1}{2} \begin{pmatrix} 
		1 & -1 \\ i & i
	\end{pmatrix}  \begin{pmatrix} 
		1 & 0 \\ 0 & -1 
	\end{pmatrix} \begin{pmatrix} 
		1 & -i \\ -1 & -i
	\end{pmatrix} = \frac{1}{2} \begin{pmatrix} 
		0 & -2i \\ 2i & 0
	\end{pmatrix} = \sigma_2
\end{align*}
\\
Qui donne :
\begin{align*}
	2\rho_P(\theta, \chi) &= id - \cos(2\theta) \sin(2\chi) U^\dagger \sigma_1 U - \sin(2\theta) \sin(2\chi) U^\dagger \sigma_2 U + \cos (2\chi) U^\dagger \sigma_3 U \\
	&= id + \cos(2\theta) \sin(-2\chi) \sigma_3 + \sin(2\theta) \sin(-2\chi)  \sigma_1 + \cos (-2\chi) \sigma_2 \\
	&= id + \sin(2\theta) \sin(2\chi)  \sigma_1 + \cos (2\chi) \sigma_2 + \cos(2\theta) \sin(2\chi) \sigma_3
\end{align*}
\\ 
Le tout reste cohérent et avec les notations :
\begin{align*}
	w_P(\theta, \chi) &= \begin{pmatrix}
		\sin(\theta) \cos(\chi) \\ -\sin (\chi) \\ \cos(\theta) \cos(\chi)
	\end{pmatrix}  &   w_B\big( \alpha, \beta \big) = \begin{pmatrix}
		\cos(\alpha) \sin(\beta) \\ \sin(\alpha) \sin(\beta) \\ \cos (\beta)
	\end{pmatrix}
\end{align*}
Cela devient :
\[w_P(2\theta, 2\chi) = \begin{pmatrix}
	1 & 0 & 0 \\ 0 & 0 & -1 \\ 0 & 1 & 0
\end{pmatrix} w_B\big( (\nicefrac{\pi}{2}-\theta ), \big(\nicefrac{\pi}{2}-\chi) \big)\]
\skipl 



\subsubsection{\todo Transformation de phases}

Première chose, le produit hermitien est invariant par $U\in\U{2}$ (si si). Ainsi :
\[\big\langle U\x(t_0), U\x(t) \big\rangle = \big\langle \x(t_0), \x(t) \big\rangle\]
\[\big\langle (U\x)', U\x \big\rangle = \big\langle U\x', U\x \big\rangle = \big\langle \x', \x \big\rangle\]
\\
Ainsi, en utilisant les formules \eqref{eq:phaset_2var} et \eqref{eq:bloch2poinca}, on a :
\begin{align*}\phaset \big(\x_B(\psi, \alpha, \beta) \big) &= \phaset \big(\x_P(\psi + \alpha/2, \alpha/2, -\beta/2) \big) \\
	&= \big( \psi + \alpha/2 \big)(t) - \big( \psi + \alpha/2 \big)(t_0) - \arctan\left( \tan \frac{\Delta\theta}{2} \frac{ \tan 2\beta(t_0)+\tan 2\chi(t)}{1 + \tan 2\beta(t_0)\tan 2\beta(t)}\right)
\end{align*}
Mais avec un calcul immédiat, on a aussi :
\[aoerinagrqobne\]
\\
Avec la formule de la phase dynamique dans Poincaré \eqref{eq:phased_2var}, on a :
\begin{align*}
	%\phaset \big(\x_B(\psi, \alpha, \beta) \big) &= \phaset \big(\x_P(\psi + \alpha/2, \alpha/2, -\beta/2) \big) 
	%\\ \\
	\phased \big(\x_B(\psi, \alpha, \beta) \big) &= \Im m \int_{t_0}^t \left\langle \frac{d}{ds}\x_B(\psi, \alpha, \beta), \x_B(\psi, \alpha, \beta) \right\rangle ds \\
	&= \Im m \int_{t_0}^t \left\langle \frac{d}{ds}\x_P(\psi + \alpha/2, \alpha/2, -\beta/2), \x_P(\psi + \alpha/2, \alpha/2, -\beta/2) \right\rangle ds \\
	&= \phased \big( \x_P(\psi + \alpha/2, \alpha/2, -\beta/2) \big) \\
	&= \psi(t) + \alpha(t)/2 - \big( \psi(t_0) + \alpha(t_0)/2 \big) - \int_{t_0}^t \frac{\alpha'(s)}{2} \sin \big( -2\beta(s)/2 \big) ds \\
	&= \psi(t) - \psi(t_0) + \frac{\alpha(t) - \alpha(t_0)}{2} + \frac{1}{2} \int_{t_0}^t \alpha'(s)\sin \beta(s) ds
\end{align*}
\\
Mais dans le même temps, si on calcul la phase dynamique de $\x_B$, on tombe cette fois sur :
\begin{align*}
	\phased\big(\x_B(\psi, \alpha, \beta) \big) &= \psi(t) - \psi(t_0) +  \int_{t_0}^t \alpha'(s) \frac{1 - \cos\beta(s)}{2}ds \\
	&= \psi(t) - \psi(t_0) + \frac{\alpha(t) - \alpha(t_0)}{2}- \frac{1}{2} \int_{t_0}^t \alpha'(s) \cos\beta(s) ds 
\end{align*}
Auquel cas :
\begin{align*}
	\phased\big(\x_S(\varphi, \theta, \chi) \big) &= \phased\big(\x_B(\varphi-\theta, 2\theta, -2\chi) \big) \\
	&= \varphi(t) - \theta(t) - \big( \varphi(t_0) - \theta(t_0) \big) + \frac{1}{2} \int_{t_0}^t 2\theta' (1 - \cos2\chi)ds \\
	&= \varphi(t) - \varphi(t_0) - \big( \theta(t) - \theta(t_0) \big) + \int_{t_0}^t \theta' (1 - \cos2\chi)ds \\
	&= \varphi(t) - \varphi(t_0) - \big( \theta(t) - \theta(t_0) \big) + \big( \theta(t) - \theta(t_0) \big) - \int_{t_0}^t \theta' \cos2\chi ds \\
	&= \varphi(t) - \varphi(t_0) - \int_{t_0}^t \theta' \cos2\chi ds
\end{align*}
Ce qui voudrait dire que :
\[\phased\big(\x_S(\varphi, \theta, \chi) \big) = \varphi(t) - \varphi(t_0) + \int_{t_0}^t \theta' \sin2\chi ds = \varphi(t) - \varphi(t_0) - \int_{t_0}^t \theta' \cos2\chi ds\]
... bizarre


\section{\wip Variété différentielle complexe }\label{ann:VDC}

\thoughts{Pas sur que je la garde cette annexe, c'est beaucoup de math pour pas grande chose... enfin c'est plus rigoureux mais pas sur que ca serve le propos vraiment.}
\\ \\
\textit{Pour plus de détails, voir \cite{nakahara_geometry_2003, ballmann_lectures_2006}.}
\\

$\manu$ sera une \emph{variété différentielle complexe} si elle satisfait les propriétés ci-dessus où $\R^n$ est remplacé par $\C^n$ et où la condition de difféomorphisme est remplacée par la condition d'holomorphisme. 
\\
Une application $f : \C^n\lr \C^n$ étant holomorphe si chacune de ses composantes vérifie l'équation de Cauchy-Riemann :
\[\forall x,y\in\R^n,\ \forall \mu,\qquad \frac{\partial f }{\partial y^\mu}(x+iy) = i \frac{\partial f }{\partial x^\mu}(x+iy)\]
\\
Les fonctions holomorphes étant automatiquement $C^\infty$, les variétés différentielles complexes sont toujours lisse, c'est-à-dire $C^\infty$. Aussi, $\manu$ est dite de dimension complexe $n$ et dimension (réel) $2n$, notés :
\begin{align}\label{eq:manuC-base_cano}
	\dim[\C](\manu) &\defeq n  &  \dim[\R] (\manu) \defeq \dim (\manu) = 2n
\end{align}
\\

Ensuite, pour le dire rapidement, la structure complexe de $\manu$ permet de séparer les espaces tangents en deux sous espaces. Pour ce faire, on commence par noter qu'en tout point $p\in\manu$ de coordonnée $z^\nu=x^\nu+iy^\nu$, l'espace tangent $\tg[p]{\manu}$, vu comme variété réelle, admet une base :
\begin{equation}
	\tg[p]{\manu} = \vec \left\{ \frac{\partial}{\partial x^1}, \cdots, \frac{\partial}{\partial x^n}, \frac{\partial}{\partial y^1}, \cdots,  \frac{\partial}{\partial y^n} \right\}
\end{equation}
\\
Plus tôt que de se basé sur les $x^\mu$ et $y^\mu$ pour séparer les $\tg[p]{\manu}$, on définit sur ces derniers un tenseur $J_p$ de type (1,1) tel que :
\begin{align}
	J_p \frac{\partial}{\partial x^\mu} &= \frac{\partial}{\partial y^\mu}  &  J_p \frac{\partial}{\partial y^\mu} &= -\frac{\partial}{\partial x^\mu}
\end{align}
\\
Ce tenseur est l'équivalent de la multiplication par $\pm i$ et le fait que $\manu$ soit complexe assure qu'il soit défini globalement, \ie~sur $\tg{\manu}$. Il est diagonaliseable dans la base :
\begin{align}\label{eq:manuC-base_holo}
	\partial_\mu = \frac{\partial}{\partial z^\mu} &\defeq \frac{1}{2}\left( \frac{\partial}{\partial x^\mu} - i\frac{\partial}{\partial y^\mu} \right)  
	&  
	\partial_{\bar{\mu}} = \frac{\partial}{\partial \overline{z}^\mu} &\defeq \frac{1}{2}\left( \frac{\partial}{\partial x^\mu} + i\frac{\partial}{\partial y^\mu} \right)
\end{align}
\\
Ainsi en fonction de la base (\eqref{eq:manuC-base_cano} ou \eqref{eq:manuC-base_holo}), $J_p$ va s'écrire :
\begin{align}
	J_p &= \begin{pmatrix}
		\text{\large\ 0\ }\Big. & I_n \\ -I_n & \text{\large\ 0\ }\Big.
	\end{pmatrix}  &
	J_p &= \begin{pmatrix}
		iI_n & \text{\large\ 0\ }\Big. \\ \text{\large\ 0\ }\Big. & -iI_n
	\end{pmatrix} 
\end{align}
\\
Finalement, $\tg{\manu}$ peut être séparé en deux sous-espaces engendré respectivement par les $\partial_\mu$ et $\partial_{\bar{\nu}}$. On parle de vecteur holomorphe et anti-holomorphe et on note :
\begin{align}
	\tg[p]{\manu}^+ &= \Vec\big\{ \partial_\mu\ |\ 1\leq \mu\leq n \big\}  &  \tg[p]{\manu}^- &= \Vec\big\{ \partial_{\bar{\mu}}\ |\ 1\leq \mu\leq n \big\}
\end{align}
\\ \\

forme kahlerienne :
\begin{equation}
	\Omega = g_{\mu \congu{\alpha}} {J^{\congu{\alpha}}}_{\congu{\nu}} dw^\mu \wedge d\congu{w}^\nu
\end{equation}
sur $\PC{n}$ :
\[\Omega(w) = i\frac{(1+w^\alpha \congu{w}_\alpha)\delta_{\mu\nu} - w_\mu \congu{w}_\nu}{(1+w^\alpha \congu{w}_\alpha)^2} dw^\mu \wedge d\congu{w}^\nu\]
\skipl


\subsection{\wip Idem que \ref{ann:phaseg=aire} depuis $\S{n}$ (plus simple, mais j'arrive à finir le calcul)} \label{ann:wedge2conn}

Cela étant dit, plutôt que de faire le calcul dans $\PC{n}$, qui demanderait de calculer les $\locconn_i = {\sigma_i}^*\conn$, le plus simple est encore de se ramener dans $\S{n}$ :
\[\oint \locconn_{i\, \rho}(\dot{\rho}) = \oint \omega_{\sigma_i(\rho)}\big(\sigma_{i*}(\dot{\rho})\big)\]
\\
Où, en notant $\ z = \sigma_i(\rho)^\mu\ $ et $\ dz = \sigma_{i*}(\dot{\rho})\ $,  $\conn$ s'écrit en coordonnées locales :
\begin{align*}
	\conn_z(dz) = i\Im m \langle dz , z\rangle &= \frac{1}{2}\Big( \langle dz , z \rangle - \langle z, dz \rangle \Big) \\
	&= \frac{1}{2}\Big( \delta_{\mu\nu} \congu{z}^\nu dz^\mu -  \delta_{\mu\nu} z^\mu d\congu{z}^\nu \Big) \\
	&= \frac{1}{2}\Big( \congu{z}_\nu dz^\mu -  z_\nu d\congu{z}^\nu \Big)
\end{align*}
\\

Donc $\conn$ à pour coefficient :
\begin{align} \label{eq:sym2conn}
	\conn_\mu &= \frac{1}{2} \congu{z}_\mu  &  \conn_{\congu{\nu}} &= - \frac{1}{2} z_\nu = -\congu{\conn_\nu}
\end{align}
\\
Ce qui donne pour dérivée extérieure :
\begin{align*}
	d\conn &= \partial_\lambda\conn_\mu\, dz^\lambda \wedge dz^\mu 
	+ \partial_\lambda\conn_{\congu{\nu}}\, dz^\lambda \wedge d\congu{z}^\nu
	+ \partial_{\congu{\lambda}}\conn_\mu\, d\congu{z}^\lambda \wedge dz^\mu 
	+ \partial_{\congu{\lambda}}\conn_{\congu{\nu}}\, d\congu{z}^\lambda \wedge d\congu{z}^\nu
\end{align*}
\\
avec :
\begin{align*}
	\partial_\lambda \conn_\mu &= \frac{1}{2}\partial_\lambda \congu{z}_\mu = 0   &
	\partial_\lambda\conn_{\congu{\nu}} &= -\frac{1}{2}\partial_\lambda z_\nu = -\delta_{\lambda \nu} \\
	\partial_{\congu{\lambda}}\conn_\mu &= \frac{1}{2}\partial_{\congu{\lambda}} \congu{z}_\mu = \delta_{\lambda \mu}  &
	\partial_{\congu{\lambda}} \conn_{\congu{\nu}} &= -\frac{1}{2}\partial_{\congu{\lambda}} z_\nu = 0
\end{align*}
\\
D'où le résultat :
\begin{align*}
	d\conn &= \partial_\lambda\conn_\mu\, dz^\lambda \wedge dz^\mu 
	+ \partial_\lambda\conn_{\congu{\nu}}\, dz^\lambda \wedge d\congu{z}^\nu
	+ \partial_{\congu{\lambda}}\conn_\mu\, d\congu{z}^\lambda \wedge dz^\mu 
	+ \partial_{\congu{\lambda}}\conn_{\congu{\nu}}\, d\congu{z}^\lambda \wedge d\congu{z}^\nu \\
	&= -\frac{1}{2}\delta_{\lambda \nu}\, dz^\lambda \wedge d\congu{z}^\nu
	+ \frac{1}{2}\delta_{\lambda \mu}\, d\congu{z}^\lambda \wedge dz^\mu \\
	&= -\frac{1}{2}\Big( \delta_{\lambda \nu}\, dz^\lambda \wedge d\congu{z}^\nu + \delta_{\mu \lambda}\, dz^\mu \wedge d\congu{z}^\lambda \Big)  &  &\text{par anti-symétrique de $\wedge$}\\
	&= -\delta_{\mu \nu}\, dz^\mu \wedge d\congu{z}^\nu  &  &\text{par simple changement de notations}
\end{align*}
\skipl

Pour ramener le résultat dans $\PC{n}$, on a :
\begin{align*}
	d\locconn_i(w) &= d(\sigma_i^* \conn_{\sigma_i(w)}) \\
	&= \sigma_i^* (d\conn_{\sigma_i(w)}) \\
	&= d\conn_{\sigma_i(w)}\circ \sigma_{i*}  \\
	\Lr\ d\locconn_i(w)_\mu &= {\sigma_{i*}}^\alpha \big( d\conn_{\sigma_i(w)} \big)_{\alpha\mu}
	\\ \\
	&= \sigma_i^* \big( -\delta_{\mu \nu}\, dz^\mu \wedge d\congu{z}^\nu \big) \\
	&= -\delta_{\mu \nu}\, \sigma_i^* (dz^\mu) \wedge \sigma_{i*}(d\congu{z}^\nu) \\
	&= -\delta_{\mu \nu}\,  \Big( 
	dw^\alpha {\sigma_{i*}}_{\alpha}^\mu + d\congu{w}^\beta {\sigma_{i*}}_{\congu{\beta}}^\mu 
	\Big) \wedge \Big(
	dw^\lambda {\sigma_{i*}}_{\lambda}^{\congu{\nu}} + d\congu{w}^\kappa {\sigma_{i*}}_{\congu{\kappa}}^{\congu{\nu}} \Big) \\
	&= -\delta_{\mu \nu}\,  \Big(
	{\sigma_{i*}}_{\alpha}^\mu {\sigma_{i*}}_{\lambda}^{\congu{\nu}} 
	dw^\alpha \wedge dw^\lambda + 
	{\sigma_{i*}}_{\alpha}^\mu {\sigma_{i*}}_{\congu{\kappa}}^{\congu{\nu}}
	dw^\alpha \wedge d\congu{w}^\kappa + 
	{\sigma_{i*}}_{\congu{\beta}}^\mu {\sigma_{i*}}_{\lambda}^{\congu{\nu}}
	d\congu{w}^\beta  \wedge dw^\lambda +
	{\sigma_{i*}}_{\congu{\beta}}^\mu {\sigma_{i*}}_{\congu{\kappa}}^{\congu{\nu}} 
	d\congu{w}^\beta \wedge d\congu{w}^\kappa 
	\Big) \\
\end{align*}
\\ \\ \\
Enfin, comme $\pi$ est une submersion riemannienne, l'on retombe sur :
\[d\locconn_i(w) = d\sigma_{i*}\conn_w = -\delta_{\mu \nu}\, dz^\mu \wedge d\congu{z}^\nu = -g_{\mu \congu{\nu}}(w) dw^\mu \wedge d\congu{w}^\nu = i\Omega(w)\]
\skipl